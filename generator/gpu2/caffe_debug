I1016 23:30:54.778951 14954 caffe.cpp:410] Use GPU with device ID 2
I1016 23:30:55.350590 14954 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer x_test
I1016 23:30:55.350627 14954 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer y_test
I1016 23:30:55.350637 14954 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1016 23:30:55.350735 14954 net.cpp:53] Initializing net from parameters: 
name: "DummyNetbyHand"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "x_train"
  type: "DummyData"
  top: "data"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 256
      dim: 188
      dim: 16
      dim: 16
    }
  }
}
layer {
  name: "y_train"
  type: "DummyData"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 256
    }
  }
}
layer {
  name: "IP"
  type: "InnerProduct"
  bottom: "data"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 114
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "RELU"
  type: "ReLU"
  bottom: "ip2"
  top: "relu1"
}
layer {
  name: "IP2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 2690
    weight_filler {
      type: "gaussian"
    }
    bias_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "SOFTMAX"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1016 23:30:55.350809 14954 layer_factory.hpp:77] Creating layer x_train
I1016 23:30:55.350833 14954 net.cpp:86] Creating Layer x_train
I1016 23:30:55.350843 14954 net.cpp:382] x_train -> data
I1016 23:30:55.417444 14954 net.cpp:124] Setting up x_train
I1016 23:30:55.417516 14954 net.cpp:131] Top shape: 256 188 16 16 (12320768)
I1016 23:30:55.417523 14954 net.cpp:139] Memory required for data: 49283072
I1016 23:30:55.417536 14954 layer_factory.hpp:77] Creating layer y_train
I1016 23:30:55.417559 14954 net.cpp:86] Creating Layer y_train
I1016 23:30:55.417569 14954 net.cpp:382] y_train -> label
I1016 23:30:55.417661 14954 net.cpp:124] Setting up y_train
I1016 23:30:55.417676 14954 net.cpp:131] Top shape: 256 (256)
I1016 23:30:55.417682 14954 net.cpp:139] Memory required for data: 49284096
I1016 23:30:55.417688 14954 layer_factory.hpp:77] Creating layer IP
I1016 23:30:55.417713 14954 net.cpp:86] Creating Layer IP
I1016 23:30:55.417721 14954 net.cpp:408] IP <- data
I1016 23:30:55.417738 14954 net.cpp:382] IP -> ip2
I1016 23:30:55.610898 14954 net.cpp:124] Setting up IP
I1016 23:30:55.610942 14954 net.cpp:131] Top shape: 256 114 (29184)
I1016 23:30:55.610949 14954 net.cpp:139] Memory required for data: 49400832
I1016 23:30:55.610975 14954 layer_factory.hpp:77] Creating layer RELU
I1016 23:30:55.610988 14954 net.cpp:86] Creating Layer RELU
I1016 23:30:55.610996 14954 net.cpp:408] RELU <- ip2
I1016 23:30:55.611006 14954 net.cpp:382] RELU -> relu1
I1016 23:30:55.840701 14954 net.cpp:124] Setting up RELU
I1016 23:30:55.840747 14954 net.cpp:131] Top shape: 256 114 (29184)
I1016 23:30:55.840752 14954 net.cpp:139] Memory required for data: 49517568
I1016 23:30:55.840759 14954 layer_factory.hpp:77] Creating layer IP2
I1016 23:30:55.840776 14954 net.cpp:86] Creating Layer IP2
I1016 23:30:55.840782 14954 net.cpp:408] IP2 <- relu1
I1016 23:30:55.840791 14954 net.cpp:382] IP2 -> ip1
I1016 23:30:55.850482 14954 net.cpp:124] Setting up IP2
I1016 23:30:55.850499 14954 net.cpp:131] Top shape: 256 2690 (688640)
I1016 23:30:55.850504 14954 net.cpp:139] Memory required for data: 52272128
I1016 23:30:55.850514 14954 layer_factory.hpp:77] Creating layer SOFTMAX
I1016 23:30:55.850528 14954 net.cpp:86] Creating Layer SOFTMAX
I1016 23:30:55.850533 14954 net.cpp:408] SOFTMAX <- ip1
I1016 23:30:55.850548 14954 net.cpp:408] SOFTMAX <- label
I1016 23:30:55.850565 14954 net.cpp:382] SOFTMAX -> loss
I1016 23:30:55.850582 14954 layer_factory.hpp:77] Creating layer SOFTMAX
I1016 23:30:55.852794 14954 net.cpp:124] Setting up SOFTMAX
I1016 23:30:55.852809 14954 net.cpp:131] Top shape: (1)
I1016 23:30:55.852814 14954 net.cpp:134]     with loss weight 1
I1016 23:30:55.852833 14954 net.cpp:139] Memory required for data: 52272132
I1016 23:30:55.852838 14954 net.cpp:200] SOFTMAX needs backward computation.
I1016 23:30:55.852843 14954 net.cpp:200] IP2 needs backward computation.
I1016 23:30:55.852846 14954 net.cpp:200] RELU needs backward computation.
I1016 23:30:55.852850 14954 net.cpp:200] IP needs backward computation.
I1016 23:30:55.852854 14954 net.cpp:202] y_train does not need backward computation.
I1016 23:30:55.852859 14954 net.cpp:202] x_train does not need backward computation.
I1016 23:30:55.852862 14954 net.cpp:244] This network produces output loss
I1016 23:30:55.852871 14954 net.cpp:257] Network initialization done.
I1016 23:30:55.852913 14954 caffe.cpp:422] Performing Forward
I1016 23:30:55.852921 14954 net.cpp:596]  [Forward] [x_train] top blob data data size: 49283072
I1016 23:30:55.852926 14954 net.cpp:596]  [Forward] [y_train] top blob label data size: 1024
I1016 23:30:55.861395 14954 net.cpp:596]  [Forward] [IP] top blob ip2 data size: 116736
I1016 23:30:55.861409 14954 net.cpp:610]  [Forward]  [IP] param blob 0 data size: 21946368
I1016 23:30:55.861413 14954 net.cpp:610]  [Forward]  [IP] param blob 1 data size: 456
I1016 23:30:55.861457 14954 net.cpp:596]  [Forward] [RELU] top blob relu1 data size: 116736
I1016 23:30:55.862113 14954 net.cpp:596]  [Forward] [IP2] top blob ip1 data size: 2754560
I1016 23:30:55.862126 14954 net.cpp:610]  [Forward]  [IP2] param blob 0 data size: 1226640
I1016 23:30:55.862131 14954 net.cpp:610]  [Forward]  [IP2] param blob 1 data size: 10760
I1016 23:30:55.863289 14954 net.cpp:596]  [Forward] [SOFTMAX] top blob loss data size: 4
I1016 23:30:55.863302 14954 caffe.cpp:427] Initial loss: 8.23671
I1016 23:30:55.863312 14954 caffe.cpp:428] Performing Backward
I1016 23:30:55.863356 14954 net.cpp:628]  [Backward] [SOFTMAX] bottom blob ip1 diff size: 2754560
I1016 23:30:55.863453 14954 net.cpp:628]  [Backward] [IP2] bottom blob relu1 diff size: 116736
I1016 23:30:55.863462 14954 net.cpp:641]  [Backward] [IP2] param blob 0 diff size: 1226640
I1016 23:30:55.863466 14954 net.cpp:641]  [Backward] [IP2] param blob 1 diff size: 10760
I1016 23:30:55.863498 14954 net.cpp:628]  [Backward] [RELU] bottom blob ip2 diff size: 116736
I1016 23:30:55.863797 14954 net.cpp:641]  [Backward] [IP] param blob 0 diff size: 21946368
I1016 23:30:55.863809 14954 net.cpp:641]  [Backward] [IP] param blob 1 diff size: 456
I1016 23:30:55.863813 14954 caffe.cpp:436] *** Benchmark begins ***
I1016 23:30:55.863817 14954 caffe.cpp:437] Testing for 10 iterations.
I1016 23:30:55.867256 14954 caffe.cpp:465] Iteration: 1 forward-backward time: 2.90781 ms.
I1016 23:30:55.870189 14954 caffe.cpp:465] Iteration: 2 forward-backward time: 2.90173 ms.
I1016 23:30:55.873123 14954 caffe.cpp:465] Iteration: 3 forward-backward time: 2.90733 ms.
I1016 23:30:55.876050 14954 caffe.cpp:465] Iteration: 4 forward-backward time: 2.90237 ms.
I1016 23:30:55.878979 14954 caffe.cpp:465] Iteration: 5 forward-backward time: 2.9033 ms.
I1016 23:30:55.881893 14954 caffe.cpp:465] Iteration: 6 forward-backward time: 2.88854 ms.
I1016 23:30:55.884817 14954 caffe.cpp:465] Iteration: 7 forward-backward time: 2.89843 ms.
I1016 23:30:55.887730 14954 caffe.cpp:465] Iteration: 8 forward-backward time: 2.88922 ms.
I1016 23:30:55.890652 14954 caffe.cpp:465] Iteration: 9 forward-backward time: 2.89648 ms.
I1016 23:30:55.893573 14954 caffe.cpp:465] Iteration: 10 forward-backward time: 2.89597 ms.
I1016 23:30:55.893589 14954 caffe.cpp:468] Average time per layer: 
I1016 23:30:55.893592 14954 caffe.cpp:472]  [time]    x_train	forward: 0.0016608 ms.
I1016 23:30:55.893600 14954 caffe.cpp:474]    x_train	backward: 0.001552 ms.
I1016 23:30:55.893610 14954 caffe.cpp:472]  [time]    y_train	forward: 0.001536 ms.
I1016 23:30:55.893620 14954 caffe.cpp:474]    y_train	backward: 0.0015904 ms.
I1016 23:30:55.893623 14954 caffe.cpp:472]  [time]         IP	forward: 1.76062 ms.
I1016 23:30:55.893627 14954 caffe.cpp:474]         IP	backward: 0.508682 ms.
I1016 23:30:55.893631 14954 caffe.cpp:472]  [time]       RELU	forward: 0.0108192 ms.
I1016 23:30:55.893635 14954 caffe.cpp:474]       RELU	backward: 0.01072 ms.
I1016 23:30:55.893640 14954 caffe.cpp:472]  [time]        IP2	forward: 0.125302 ms.
I1016 23:30:55.893643 14954 caffe.cpp:474]        IP2	backward: 0.173389 ms.
I1016 23:30:55.893647 14954 caffe.cpp:472]  [time]    SOFTMAX	forward: 0.158387 ms.
I1016 23:30:55.893651 14954 caffe.cpp:474]    SOFTMAX	backward: 0.0578112 ms.
I1016 23:30:55.893661 14954 caffe.cpp:480] Average Forward pass: 2.09538 ms.
I1016 23:30:55.893666 14954 caffe.cpp:482] Average Backward pass: 0.790499 ms.
I1016 23:30:55.893673 14954 caffe.cpp:484] Average Forward-Backward: 2.93192 ms.
I1016 23:30:55.893681 14954 caffe.cpp:486] Total Time: 29.3192 ms.
I1016 23:30:55.893685 14954 caffe.cpp:487] *** Benchmark ends ***
