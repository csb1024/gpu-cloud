I1016 23:32:01.938977 15100 caffe.cpp:410] Use GPU with device ID 0
I1016 23:32:02.559748 15100 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer x_test
I1016 23:32:02.559790 15100 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer y_test
I1016 23:32:02.559801 15100 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1016 23:32:02.559904 15100 net.cpp:53] Initializing net from parameters: 
name: "DummyNetbyHand"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "x_train"
  type: "DummyData"
  top: "data"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 16
      dim: 11
      dim: 14
      dim: 14
    }
  }
}
layer {
  name: "y_train"
  type: "DummyData"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 16
    }
  }
}
layer {
  name: "IP"
  type: "InnerProduct"
  bottom: "data"
  top: "ip2"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 3387
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "RELU"
  type: "ReLU"
  bottom: "ip2"
  top: "relu1"
}
layer {
  name: "IP2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 748
    weight_filler {
      type: "gaussian"
    }
    bias_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "SOFTMAX"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1016 23:32:02.559979 15100 layer_factory.hpp:77] Creating layer x_train
I1016 23:32:02.560003 15100 net.cpp:86] Creating Layer x_train
I1016 23:32:02.560012 15100 net.cpp:382] x_train -> data
I1016 23:32:02.594257 15100 net.cpp:124] Setting up x_train
I1016 23:32:02.594314 15100 net.cpp:131] Top shape: 16 11 14 14 (34496)
I1016 23:32:02.594322 15100 net.cpp:139] Memory required for data: 137984
I1016 23:32:02.594336 15100 layer_factory.hpp:77] Creating layer y_train
I1016 23:32:02.594358 15100 net.cpp:86] Creating Layer y_train
I1016 23:32:02.594367 15100 net.cpp:382] y_train -> label
I1016 23:32:02.594427 15100 net.cpp:124] Setting up y_train
I1016 23:32:02.594441 15100 net.cpp:131] Top shape: 16 (16)
I1016 23:32:02.594447 15100 net.cpp:139] Memory required for data: 138048
I1016 23:32:02.594454 15100 layer_factory.hpp:77] Creating layer IP
I1016 23:32:02.594471 15100 net.cpp:86] Creating Layer IP
I1016 23:32:02.594480 15100 net.cpp:408] IP <- data
I1016 23:32:02.594498 15100 net.cpp:382] IP -> ip2
I1016 23:32:02.851932 15100 net.cpp:124] Setting up IP
I1016 23:32:02.851982 15100 net.cpp:131] Top shape: 16 3387 (54192)
I1016 23:32:02.851989 15100 net.cpp:139] Memory required for data: 354816
I1016 23:32:02.852018 15100 layer_factory.hpp:77] Creating layer RELU
I1016 23:32:02.852037 15100 net.cpp:86] Creating Layer RELU
I1016 23:32:02.852044 15100 net.cpp:408] RELU <- ip2
I1016 23:32:02.852054 15100 net.cpp:382] RELU -> relu1
I1016 23:32:03.110260 15100 net.cpp:124] Setting up RELU
I1016 23:32:03.110311 15100 net.cpp:131] Top shape: 16 3387 (54192)
I1016 23:32:03.110316 15100 net.cpp:139] Memory required for data: 571584
I1016 23:32:03.110324 15100 layer_factory.hpp:77] Creating layer IP2
I1016 23:32:03.110344 15100 net.cpp:86] Creating Layer IP2
I1016 23:32:03.110350 15100 net.cpp:408] IP2 <- relu1
I1016 23:32:03.110360 15100 net.cpp:382] IP2 -> ip1
I1016 23:32:03.175695 15100 net.cpp:124] Setting up IP2
I1016 23:32:03.175724 15100 net.cpp:131] Top shape: 16 748 (11968)
I1016 23:32:03.175729 15100 net.cpp:139] Memory required for data: 619456
I1016 23:32:03.175742 15100 layer_factory.hpp:77] Creating layer SOFTMAX
I1016 23:32:03.175758 15100 net.cpp:86] Creating Layer SOFTMAX
I1016 23:32:03.175765 15100 net.cpp:408] SOFTMAX <- ip1
I1016 23:32:03.175779 15100 net.cpp:408] SOFTMAX <- label
I1016 23:32:03.175788 15100 net.cpp:382] SOFTMAX -> loss
I1016 23:32:03.175819 15100 layer_factory.hpp:77] Creating layer SOFTMAX
I1016 23:32:03.177440 15100 net.cpp:124] Setting up SOFTMAX
I1016 23:32:03.177456 15100 net.cpp:131] Top shape: (1)
I1016 23:32:03.177461 15100 net.cpp:134]     with loss weight 1
I1016 23:32:03.177479 15100 net.cpp:139] Memory required for data: 619460
I1016 23:32:03.177484 15100 net.cpp:200] SOFTMAX needs backward computation.
I1016 23:32:03.177489 15100 net.cpp:200] IP2 needs backward computation.
I1016 23:32:03.177494 15100 net.cpp:200] RELU needs backward computation.
I1016 23:32:03.177497 15100 net.cpp:200] IP needs backward computation.
I1016 23:32:03.177502 15100 net.cpp:202] y_train does not need backward computation.
I1016 23:32:03.177506 15100 net.cpp:202] x_train does not need backward computation.
I1016 23:32:03.177510 15100 net.cpp:244] This network produces output loss
I1016 23:32:03.177520 15100 net.cpp:257] Network initialization done.
I1016 23:32:03.177563 15100 caffe.cpp:422] Performing Forward
I1016 23:32:03.177572 15100 net.cpp:596]  [Forward] [x_train] top blob data data size: 137984
I1016 23:32:03.177577 15100 net.cpp:596]  [Forward] [y_train] top blob label data size: 64
I1016 23:32:03.180958 15100 net.cpp:596]  [Forward] [IP] top blob ip2 data size: 216768
I1016 23:32:03.180970 15100 net.cpp:610]  [Forward]  [IP] param blob 0 data size: 29209488
I1016 23:32:03.180975 15100 net.cpp:610]  [Forward]  [IP] param blob 1 data size: 13548
I1016 23:32:03.181020 15100 net.cpp:596]  [Forward] [RELU] top blob relu1 data size: 216768
I1016 23:32:03.182433 15100 net.cpp:596]  [Forward] [IP2] top blob ip1 data size: 47872
I1016 23:32:03.182446 15100 net.cpp:610]  [Forward]  [IP2] param blob 0 data size: 10133904
I1016 23:32:03.182451 15100 net.cpp:610]  [Forward]  [IP2] param blob 1 data size: 2992
I1016 23:32:03.182696 15100 net.cpp:596]  [Forward] [SOFTMAX] top blob loss data size: 4
I1016 23:32:03.182706 15100 caffe.cpp:427] Initial loss: 7.61984
I1016 23:32:03.182715 15100 caffe.cpp:428] Performing Backward
I1016 23:32:03.182750 15100 net.cpp:628]  [Backward] [SOFTMAX] bottom blob ip1 diff size: 47872
I1016 23:32:03.183079 15100 net.cpp:628]  [Backward] [IP2] bottom blob relu1 diff size: 216768
I1016 23:32:03.183090 15100 net.cpp:641]  [Backward] [IP2] param blob 0 diff size: 10133904
I1016 23:32:03.183095 15100 net.cpp:641]  [Backward] [IP2] param blob 1 diff size: 2992
I1016 23:32:03.183128 15100 net.cpp:628]  [Backward] [RELU] bottom blob ip2 diff size: 216768
I1016 23:32:03.183429 15100 net.cpp:641]  [Backward] [IP] param blob 0 diff size: 29209488
I1016 23:32:03.183440 15100 net.cpp:641]  [Backward] [IP] param blob 1 diff size: 13548
I1016 23:32:03.183445 15100 caffe.cpp:436] *** Benchmark begins ***
I1016 23:32:03.183449 15100 caffe.cpp:437] Testing for 10 iterations.
I1016 23:32:03.185093 15100 caffe.cpp:465] Iteration: 1 forward-backward time: 1.27098 ms.
I1016 23:32:03.186378 15100 caffe.cpp:465] Iteration: 2 forward-backward time: 1.25677 ms.
I1016 23:32:03.187652 15100 caffe.cpp:465] Iteration: 3 forward-backward time: 1.2511 ms.
I1016 23:32:03.188935 15100 caffe.cpp:465] Iteration: 4 forward-backward time: 1.26154 ms.
I1016 23:32:03.190271 15100 caffe.cpp:465] Iteration: 5 forward-backward time: 1.3137 ms.
I1016 23:32:03.191558 15100 caffe.cpp:465] Iteration: 6 forward-backward time: 1.26387 ms.
I1016 23:32:03.192833 15100 caffe.cpp:465] Iteration: 7 forward-backward time: 1.25325 ms.
I1016 23:32:03.194114 15100 caffe.cpp:465] Iteration: 8 forward-backward time: 1.2591 ms.
I1016 23:32:03.195399 15100 caffe.cpp:465] Iteration: 9 forward-backward time: 1.26166 ms.
I1016 23:32:03.196673 15100 caffe.cpp:465] Iteration: 10 forward-backward time: 1.25274 ms.
I1016 23:32:03.196686 15100 caffe.cpp:468] Average time per layer: 
I1016 23:32:03.196691 15100 caffe.cpp:472]  [time]    x_train	forward: 0.0018976 ms.
I1016 23:32:03.196698 15100 caffe.cpp:474]    x_train	backward: 0.001568 ms.
I1016 23:32:03.196702 15100 caffe.cpp:472]  [time]    y_train	forward: 0.0017024 ms.
I1016 23:32:03.196712 15100 caffe.cpp:474]    y_train	backward: 0.0015968 ms.
I1016 23:32:03.196723 15100 caffe.cpp:472]  [time]         IP	forward: 0.345619 ms.
I1016 23:32:03.196727 15100 caffe.cpp:474]         IP	backward: 0.304774 ms.
I1016 23:32:03.196732 15100 caffe.cpp:472]  [time]       RELU	forward: 0.0105568 ms.
I1016 23:32:03.196736 15100 caffe.cpp:474]       RELU	backward: 0.0136096 ms.
I1016 23:32:03.196740 15100 caffe.cpp:472]  [time]        IP2	forward: 0.120269 ms.
I1016 23:32:03.196744 15100 caffe.cpp:474]        IP2	backward: 0.274035 ms.
I1016 23:32:03.196748 15100 caffe.cpp:472]  [time]    SOFTMAX	forward: 0.0764096 ms.
I1016 23:32:03.196753 15100 caffe.cpp:474]    SOFTMAX	backward: 0.0183136 ms.
I1016 23:32:03.196761 15100 caffe.cpp:480] Average Forward pass: 0.596666 ms.
I1016 23:32:03.196768 15100 caffe.cpp:482] Average Backward pass: 0.653846 ms.
I1016 23:32:03.196774 15100 caffe.cpp:484] Average Forward-Backward: 1.29471 ms.
I1016 23:32:03.196780 15100 caffe.cpp:486] Total Time: 12.9471 ms.
I1016 23:32:03.196786 15100 caffe.cpp:487] *** Benchmark ends ***
