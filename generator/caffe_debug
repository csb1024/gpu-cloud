I0404 22:21:57.098964  3062 caffe.cpp:218] Using GPUs 0
I0404 22:21:57.249438  3062 caffe.cpp:223] GPU 0: GeForce GTX 1080
I0404 22:21:57.847945  3062 solver.cpp:44] Initializing solver from parameters: 
test_iter: 1
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 1
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 0
snapshot_prefix: "./"
solver_mode: GPU
device_id: 0
net: "out.prototxt"
train_state {
  level: 0
  stage: ""
}
I0404 22:21:57.848013  3062 solver.cpp:87] Creating training net from net file: out.prototxt
I0404 22:21:57.848389  3062 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer x_test
I0404 22:21:57.848404  3062 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer y_test
I0404 22:21:57.848415  3062 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0404 22:21:57.848493  3062 net.cpp:51] Initializing net from parameters: 
name: "DummyNetbyHand"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "x_train"
  type: "DummyData"
  top: "data"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 101
      dim: 3
      dim: 85
      dim: 85
    }
  }
}
layer {
  name: "y_train"
  type: "DummyData"
  top: "label"
  include {
    phase: TRAIN
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 101
    }
  }
}
layer {
  name: "CONV"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 57
    kernel_size: 8
    stride: 1
    weight_filler {
      type: "gaussian"
    }
    bias_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "POOLING"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "IP"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 795
    weight_filler {
      type: "gaussian"
    }
    bias_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0404 22:21:57.848564  3062 layer_factory.hpp:77] Creating layer x_train
I0404 22:21:57.848587  3062 net.cpp:84] Creating Layer x_train
I0404 22:21:57.848604  3062 net.cpp:380] x_train -> data
I0404 22:21:57.856106  3062 net.cpp:122] Setting up x_train
I0404 22:21:57.856142  3062 net.cpp:129] Top shape: 101 3 85 85 (2189175)
I0404 22:21:57.856149  3062 net.cpp:137] Memory required for data: 8756700
I0404 22:21:57.856159  3062 layer_factory.hpp:77] Creating layer y_train
I0404 22:21:57.856176  3062 net.cpp:84] Creating Layer y_train
I0404 22:21:57.856184  3062 net.cpp:380] y_train -> label
I0404 22:21:57.856250  3062 net.cpp:122] Setting up y_train
I0404 22:21:57.856264  3062 net.cpp:129] Top shape: 101 (101)
I0404 22:21:57.856271  3062 net.cpp:137] Memory required for data: 8757104
I0404 22:21:57.856276  3062 layer_factory.hpp:77] Creating layer CONV
I0404 22:21:57.856293  3062 net.cpp:84] Creating Layer CONV
I0404 22:21:57.856302  3062 net.cpp:406] CONV <- data
I0404 22:21:57.856318  3062 net.cpp:380] CONV -> conv1
I0404 22:21:58.203022  3062 net.cpp:122] Setting up CONV
I0404 22:21:58.203099  3062 net.cpp:129] Top shape: 101 57 78 78 (35025588)
I0404 22:21:58.203106  3062 net.cpp:137] Memory required for data: 148859456
I0404 22:21:58.203131  3062 layer_factory.hpp:77] Creating layer POOLING
I0404 22:21:58.203181  3062 net.cpp:84] Creating Layer POOLING
I0404 22:21:58.203189  3062 net.cpp:406] POOLING <- conv1
I0404 22:21:58.203199  3062 net.cpp:380] POOLING -> pool1
I0404 22:21:58.203271  3062 net.cpp:122] Setting up POOLING
I0404 22:21:58.203284  3062 net.cpp:129] Top shape: 101 57 39 39 (8756397)
I0404 22:21:58.203289  3062 net.cpp:137] Memory required for data: 183885044
I0404 22:21:58.203294  3062 layer_factory.hpp:77] Creating layer IP
I0404 22:21:58.203353  3062 net.cpp:84] Creating Layer IP
I0404 22:21:58.203361  3062 net.cpp:406] IP <- pool1
I0404 22:21:58.203369  3062 net.cpp:380] IP -> ip2
I0404 22:21:59.968155  3062 net.cpp:122] Setting up IP
I0404 22:21:59.968211  3062 net.cpp:129] Top shape: 101 795 (80295)
I0404 22:21:59.968217  3062 net.cpp:137] Memory required for data: 184206224
I0404 22:21:59.968237  3062 layer_factory.hpp:77] Creating layer loss
I0404 22:21:59.968262  3062 net.cpp:84] Creating Layer loss
I0404 22:21:59.968269  3062 net.cpp:406] loss <- ip2
I0404 22:21:59.968276  3062 net.cpp:406] loss <- label
I0404 22:21:59.968305  3062 net.cpp:380] loss -> loss
I0404 22:21:59.968336  3062 layer_factory.hpp:77] Creating layer loss
I0404 22:21:59.969830  3062 net.cpp:122] Setting up loss
I0404 22:21:59.969843  3062 net.cpp:129] Top shape: (1)
I0404 22:21:59.969848  3062 net.cpp:132]     with loss weight 1
I0404 22:21:59.969882  3062 net.cpp:137] Memory required for data: 184206228
I0404 22:21:59.969888  3062 net.cpp:198] loss needs backward computation.
I0404 22:21:59.969892  3062 net.cpp:198] IP needs backward computation.
I0404 22:21:59.969897  3062 net.cpp:198] POOLING needs backward computation.
I0404 22:21:59.969902  3062 net.cpp:198] CONV needs backward computation.
I0404 22:21:59.969905  3062 net.cpp:200] y_train does not need backward computation.
I0404 22:21:59.969909  3062 net.cpp:200] x_train does not need backward computation.
I0404 22:21:59.969913  3062 net.cpp:242] This network produces output loss
I0404 22:21:59.969921  3062 net.cpp:255] Network initialization done.
I0404 22:21:59.970336  3062 solver.cpp:173] Creating test net (#0) specified by net file: out.prototxt
I0404 22:21:59.970360  3062 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer x_train
I0404 22:21:59.970366  3062 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer y_train
I0404 22:21:59.970432  3062 net.cpp:51] Initializing net from parameters: 
name: "DummyNetbyHand"
state {
  phase: TEST
}
layer {
  name: "x_test"
  type: "DummyData"
  top: "data"
  include {
    phase: TEST
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 101
      dim: 3
      dim: 85
      dim: 85
    }
  }
}
layer {
  name: "y_test"
  type: "DummyData"
  top: "label"
  include {
    phase: TEST
  }
  dummy_data_param {
    data_filler {
      type: "constant"
    }
    shape {
      dim: 101
    }
  }
}
layer {
  name: "CONV"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 57
    kernel_size: 8
    stride: 1
    weight_filler {
      type: "gaussian"
    }
    bias_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "POOLING"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "IP"
  type: "InnerProduct"
  bottom: "pool1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 1
  }
  inner_product_param {
    num_output: 795
    weight_filler {
      type: "gaussian"
    }
    bias_filler {
      type: "gaussian"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0404 22:21:59.970489  3062 layer_factory.hpp:77] Creating layer x_test
I0404 22:21:59.970499  3062 net.cpp:84] Creating Layer x_test
I0404 22:21:59.970504  3062 net.cpp:380] x_test -> data
I0404 22:21:59.975163  3062 net.cpp:122] Setting up x_test
I0404 22:21:59.975179  3062 net.cpp:129] Top shape: 101 3 85 85 (2189175)
I0404 22:21:59.975184  3062 net.cpp:137] Memory required for data: 8756700
I0404 22:21:59.975188  3062 layer_factory.hpp:77] Creating layer y_test
I0404 22:21:59.975199  3062 net.cpp:84] Creating Layer y_test
I0404 22:21:59.975206  3062 net.cpp:380] y_test -> label
I0404 22:21:59.975260  3062 net.cpp:122] Setting up y_test
I0404 22:21:59.975278  3062 net.cpp:129] Top shape: 101 (101)
I0404 22:21:59.975282  3062 net.cpp:137] Memory required for data: 8757104
I0404 22:21:59.975286  3062 layer_factory.hpp:77] Creating layer label_y_test_0_split
I0404 22:21:59.975292  3062 net.cpp:84] Creating Layer label_y_test_0_split
I0404 22:21:59.975297  3062 net.cpp:406] label_y_test_0_split <- label
I0404 22:21:59.975302  3062 net.cpp:380] label_y_test_0_split -> label_y_test_0_split_0
I0404 22:21:59.975309  3062 net.cpp:380] label_y_test_0_split -> label_y_test_0_split_1
I0404 22:21:59.975342  3062 net.cpp:122] Setting up label_y_test_0_split
I0404 22:21:59.975349  3062 net.cpp:129] Top shape: 101 (101)
I0404 22:21:59.975354  3062 net.cpp:129] Top shape: 101 (101)
I0404 22:21:59.975358  3062 net.cpp:137] Memory required for data: 8757912
I0404 22:21:59.975361  3062 layer_factory.hpp:77] Creating layer CONV
I0404 22:21:59.975371  3062 net.cpp:84] Creating Layer CONV
I0404 22:21:59.975375  3062 net.cpp:406] CONV <- data
I0404 22:21:59.975383  3062 net.cpp:380] CONV -> conv1
I0404 22:21:59.976682  3062 net.cpp:122] Setting up CONV
I0404 22:21:59.976698  3062 net.cpp:129] Top shape: 101 57 78 78 (35025588)
I0404 22:21:59.976703  3062 net.cpp:137] Memory required for data: 148860264
I0404 22:21:59.976713  3062 layer_factory.hpp:77] Creating layer POOLING
I0404 22:21:59.976722  3062 net.cpp:84] Creating Layer POOLING
I0404 22:21:59.976727  3062 net.cpp:406] POOLING <- conv1
I0404 22:21:59.976733  3062 net.cpp:380] POOLING -> pool1
I0404 22:21:59.976773  3062 net.cpp:122] Setting up POOLING
I0404 22:21:59.976779  3062 net.cpp:129] Top shape: 101 57 39 39 (8756397)
I0404 22:21:59.976783  3062 net.cpp:137] Memory required for data: 183885852
I0404 22:21:59.976788  3062 layer_factory.hpp:77] Creating layer IP
I0404 22:21:59.976796  3062 net.cpp:84] Creating Layer IP
I0404 22:21:59.976800  3062 net.cpp:406] IP <- pool1
I0404 22:21:59.976809  3062 net.cpp:380] IP -> ip2
I0404 22:22:01.710964  3062 net.cpp:122] Setting up IP
I0404 22:22:01.711015  3062 net.cpp:129] Top shape: 101 795 (80295)
I0404 22:22:01.711020  3062 net.cpp:137] Memory required for data: 184207032
I0404 22:22:01.711037  3062 layer_factory.hpp:77] Creating layer ip2_IP_0_split
I0404 22:22:01.711053  3062 net.cpp:84] Creating Layer ip2_IP_0_split
I0404 22:22:01.711060  3062 net.cpp:406] ip2_IP_0_split <- ip2
I0404 22:22:01.711068  3062 net.cpp:380] ip2_IP_0_split -> ip2_IP_0_split_0
I0404 22:22:01.711078  3062 net.cpp:380] ip2_IP_0_split -> ip2_IP_0_split_1
I0404 22:22:01.711134  3062 net.cpp:122] Setting up ip2_IP_0_split
I0404 22:22:01.711143  3062 net.cpp:129] Top shape: 101 795 (80295)
I0404 22:22:01.711148  3062 net.cpp:129] Top shape: 101 795 (80295)
I0404 22:22:01.711153  3062 net.cpp:137] Memory required for data: 184849392
I0404 22:22:01.711156  3062 layer_factory.hpp:77] Creating layer accuracy
I0404 22:22:01.711184  3062 net.cpp:84] Creating Layer accuracy
I0404 22:22:01.711189  3062 net.cpp:406] accuracy <- ip2_IP_0_split_0
I0404 22:22:01.711194  3062 net.cpp:406] accuracy <- label_y_test_0_split_0
I0404 22:22:01.711201  3062 net.cpp:380] accuracy -> accuracy
I0404 22:22:01.711211  3062 net.cpp:122] Setting up accuracy
I0404 22:22:01.711217  3062 net.cpp:129] Top shape: (1)
I0404 22:22:01.711221  3062 net.cpp:137] Memory required for data: 184849396
I0404 22:22:01.711225  3062 layer_factory.hpp:77] Creating layer loss
I0404 22:22:01.711235  3062 net.cpp:84] Creating Layer loss
I0404 22:22:01.711238  3062 net.cpp:406] loss <- ip2_IP_0_split_1
I0404 22:22:01.711243  3062 net.cpp:406] loss <- label_y_test_0_split_1
I0404 22:22:01.711249  3062 net.cpp:380] loss -> loss
I0404 22:22:01.711258  3062 layer_factory.hpp:77] Creating layer loss
I0404 22:22:01.712141  3062 net.cpp:122] Setting up loss
I0404 22:22:01.712157  3062 net.cpp:129] Top shape: (1)
I0404 22:22:01.712162  3062 net.cpp:132]     with loss weight 1
I0404 22:22:01.712173  3062 net.cpp:137] Memory required for data: 184849400
I0404 22:22:01.712177  3062 net.cpp:198] loss needs backward computation.
I0404 22:22:01.712199  3062 net.cpp:200] accuracy does not need backward computation.
I0404 22:22:01.712204  3062 net.cpp:198] ip2_IP_0_split needs backward computation.
I0404 22:22:01.712208  3062 net.cpp:198] IP needs backward computation.
I0404 22:22:01.712211  3062 net.cpp:198] POOLING needs backward computation.
I0404 22:22:01.712215  3062 net.cpp:198] CONV needs backward computation.
I0404 22:22:01.712220  3062 net.cpp:200] label_y_test_0_split does not need backward computation.
I0404 22:22:01.712224  3062 net.cpp:200] y_test does not need backward computation.
I0404 22:22:01.712229  3062 net.cpp:200] x_test does not need backward computation.
I0404 22:22:01.712231  3062 net.cpp:242] This network produces output accuracy
I0404 22:22:01.712236  3062 net.cpp:242] This network produces output loss
I0404 22:22:01.712246  3062 net.cpp:255] Network initialization done.
I0404 22:22:01.712296  3062 solver.cpp:56] Solver scaffolding done.
I0404 22:22:01.712435  3062 caffe.cpp:248] Starting Optimization
I0404 22:22:01.712442  3062 solver.cpp:273] Solving DummyNetbyHand
I0404 22:22:01.712445  3062 solver.cpp:274] Learning Rate Policy: inv
I0404 22:22:01.713264  3062 solver.cpp:331] Iteration 0, Testing net (#0)
I0404 22:22:01.713279  3062 net.cpp:676] Ignoring source layer x_train
I0404 22:22:01.713282  3062 net.cpp:676] Ignoring source layer y_train
I0404 22:22:01.787446  3062 solver.cpp:398]     Test net output #0: accuracy = 0
I0404 22:22:01.787477  3062 solver.cpp:398]     Test net output #1: loss = 87.3365 (* 1 = 87.3365 loss)
I0404 22:22:02.222596  3062 solver.cpp:219] Iteration 0 (0 iter/s, 0.510091s/100 iters), loss = 87.3365
I0404 22:22:02.222687  3062 solver.cpp:238]     Train net output #0: loss = 87.3365 (* 1 = 87.3365 loss)
I0404 22:22:02.222728  3062 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0404 22:22:02.225862  3062 solver.cpp:448] Snapshotting to binary proto file ./_iter_1.caffemodel
I0404 22:22:03.444448  3062 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ./_iter_1.solverstate
I0404 22:22:03.858605  3062 solver.cpp:316] Optimization Done.
I0404 22:22:03.858639  3062 caffe.cpp:259] Optimization Done.
